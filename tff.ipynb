{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_federated as tff\n",
    "import tensorflow_privacy as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tff.federated_computation\n",
    "def hello_world():\n",
    "    return 'Hello, World!'\n",
    "\n",
    "hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /nas/scratch/PR/hyunchan.moon/venv/tf_210_test/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /nas/scratch/PR/hyunchan.moon/venv/tf_210_test/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "def get_emnist_dataset():\n",
    "    emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(only_digits=True)\n",
    "\n",
    "    def element_fn(element):\n",
    "        return collections.OrderedDict(x=tf.expand_dims(element['pixels'], -1), y=element['label'])\n",
    "\n",
    "    def preprocess_train_dataset(dataset):\n",
    "    # Use buffer_size same as the maximum client dataset size,\n",
    "    # 418 for Federated EMNIST\n",
    "        return (dataset.map(element_fn).shuffle(buffer_size=418).repeat(1).batch(32, drop_remainder=False))\n",
    "\n",
    "    def preprocess_test_dataset(dataset):\n",
    "        return dataset.map(element_fn).batch(128, drop_remainder=False)\n",
    "\n",
    "    emnist_train = emnist_train.preprocess(preprocess_train_dataset)\n",
    "    emnist_test = preprocess_test_dataset(emnist_test.create_tf_dataset_from_all_clients())\n",
    "    \n",
    "    return emnist_train, emnist_test\n",
    "\n",
    "train_data, test_data = get_emnist_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model_fn():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Reshape(input_shape=(28, 28, 1), target_shape=(28 * 28,)),\n",
    "        tf.keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(10)])\n",
    "    return tff.learning.from_keras_model(keras_model=model,loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                                         input_spec=test_data.element_spec,\n",
    "                                         metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1691 1692\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.5 \n",
    "train_size = len(train_data.client_ids)\n",
    "train_A_size = int(train_size * split_ratio)\n",
    "train_B_size = int(train_size - train_A_size)\n",
    "\n",
    "print(train_A_size, train_B_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_per_round = 50\n",
    "\n",
    "trai_A_x = np.random.uniform(size=train_A_size)\n",
    "trai_B_x = np.random.uniform(size=train_B_size)\n",
    "\n",
    "sampling_prob_A = clients_per_round / train_A_size\n",
    "sampling_prob_B = clients_per_round / train_B_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_clients_A = [train_data.client_ids[i] for i in range(train_A_size) if trai_A_x[i] < sampling_prob_A]\n",
    "sampled_train_data_A = [train_data.create_tf_dataset_for_client(client) for client in sampled_clients_A]\n",
    "\n",
    "sampled_clients_B = [train_data.client_ids[i] for i in range(train_A_size, train_size) if trai_B_x[i-train_A_size] < sampling_prob_B]\n",
    "sampled_train_data_B = [train_data.create_tf_dataset_for_client(client) for client in sampled_clients_B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tff.backends.native.set_local_python_execution_context(clients_per_thread=5)\n",
    "\n",
    "def my_train(rounds,clients_per_round, noise_multiplier, divide_train_data, data_frame):\n",
    "    aggregation_factory = tff.learning.model_update_aggregator.dp_aggregator(noise_multiplier, clients_per_round)\n",
    "    learning_process = tff.learning.build_federated_averaging_process(my_model_fn,\n",
    "                                                                      client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.01),\n",
    "                                                                      server_optimizer_fn=lambda: tf.keras.optimizers.SGD(1.0, momentum=0.9),\n",
    "                                                                      model_update_aggregation_factory=aggregation_factory)\n",
    "    eval_process = tff.learning.build_federated_evaluation(my_model_fn)\n",
    "\n",
    "    # Training loop.\n",
    "    state = learning_process.initialize()\n",
    "    for round in range(rounds):\n",
    "        if round % 5 == 0:\n",
    "            metrics = eval_process(state.model, [test_data])['eval']\n",
    "            if round < 25 or round % 25 == 0:\n",
    "                print(f'Round {round:3d}: {metrics}')\n",
    "            data_frame = data_frame.append({'Round': round,\n",
    "                                            'NoiseMultiplier': noise_multiplier,\n",
    "                                            **metrics}, ignore_index=True)\n",
    "        # Use selected clients for update.\n",
    "        state, metrics = learning_process.next(state, divide_train_data)\n",
    "\n",
    "    metrics = eval_process(state.model, [test_data])['eval']\n",
    "    print(f'Round {rounds:3d}: {metrics}')\n",
    "    data_frame = data_frame.append({'Round': rounds,\n",
    "                                  'NoiseMultiplier': noise_multiplier,\n",
    "                                  **metrics}, ignore_index=True)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   0: OrderedDict([('sparse_categorical_accuracy', 0.086500786), ('loss', 2.3941214), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round   5: OrderedDict([('sparse_categorical_accuracy', 0.26932308), ('loss', 2.208605), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round  10: OrderedDict([('sparse_categorical_accuracy', 0.3159042), ('loss', 2.0857782), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round  15: OrderedDict([('sparse_categorical_accuracy', 0.47173786), ('loss', 1.8937052), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round  20: OrderedDict([('sparse_categorical_accuracy', 0.6440047), ('loss', 1.6490748), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round  25: OrderedDict([('sparse_categorical_accuracy', 0.63891065), ('loss', 1.4300345), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round  50: OrderedDict([('sparse_categorical_accuracy', 0.7141213), ('loss', 0.9115348), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round  75: OrderedDict([('sparse_categorical_accuracy', 0.76422906), ('loss', 0.7628789), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round 100: OrderedDict([('sparse_categorical_accuracy', 0.77488244), ('loss', 0.7243343), ('num_examples', 40832), ('num_batches', 319)])\n"
     ]
    }
   ],
   "source": [
    "data_frame = pd.DataFrame()\n",
    "rounds = 100\n",
    "\n",
    "noise_multiplier= 0.5\n",
    "\n",
    "train_A_df = my_train(rounds=rounds, clients_per_round=clients_per_round, \n",
    "                      noise_multiplier=noise_multiplier, \n",
    "                      divide_train_data=sampled_train_data_A, \n",
    "                      data_frame=data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   0: OrderedDict([('sparse_categorical_accuracy', 0.09994612), ('loss', 2.6410248), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round   5: OrderedDict([('sparse_categorical_accuracy', 0.13389009), ('loss', 2.2452726), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round  10: OrderedDict([('sparse_categorical_accuracy', 0.29854035), ('loss', 2.1380959), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round  15: OrderedDict([('sparse_categorical_accuracy', 0.47433385), ('loss', 1.9683051), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round  20: OrderedDict([('sparse_categorical_accuracy', 0.57868826), ('loss', 1.7452528), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round  25: OrderedDict([('sparse_categorical_accuracy', 0.61008525), ('loss', 1.4972601), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round  50: OrderedDict([('sparse_categorical_accuracy', 0.7277136), ('loss', 0.88016003), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round  75: OrderedDict([('sparse_categorical_accuracy', 0.7376323), ('loss', 0.8683005), ('num_examples', 40832), ('num_batches', 319)])\n",
      "Round 100: OrderedDict([('sparse_categorical_accuracy', 0.7216154), ('loss', 0.92004377), ('num_examples', 40832), ('num_batches', 319)])\n"
     ]
    }
   ],
   "source": [
    "data_frame = pd.DataFrame()\n",
    "rounds = 100\n",
    "\n",
    "noise_multiplier= 0.75\n",
    "\n",
    "train_B_df = my_train(rounds=rounds,clients_per_round=clients_per_round, \n",
    "                      noise_multiplier=noise_multiplier, divide_train_data=sampled_train_data_B, data_frame=data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NoiseMultiplier</th>\n",
       "      <th>Round</th>\n",
       "      <th>loss</th>\n",
       "      <th>num_batches</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>sparse_categorical_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.394121</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.086501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.208605</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.269323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.085778</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.315904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.893705</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.471738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.649075</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.644005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.430035</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.638911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.192684</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.667908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.066967</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.975683</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.697002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.883329</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.726734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.911535</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.714121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.906354</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.708758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.800854</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.745273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.854340</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.730971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.874084</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.726318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.762879</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.764229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.709827</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.780368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.773453</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.756294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.744702</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.766066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.707833</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.775838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.724334</td>\n",
       "      <td>319.0</td>\n",
       "      <td>40832.0</td>\n",
       "      <td>0.774882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NoiseMultiplier  Round      loss  num_batches  num_examples  \\\n",
       "0               0.5    0.0  2.394121        319.0       40832.0   \n",
       "1               0.5    5.0  2.208605        319.0       40832.0   \n",
       "2               0.5   10.0  2.085778        319.0       40832.0   \n",
       "3               0.5   15.0  1.893705        319.0       40832.0   \n",
       "4               0.5   20.0  1.649075        319.0       40832.0   \n",
       "5               0.5   25.0  1.430035        319.0       40832.0   \n",
       "6               0.5   30.0  1.192684        319.0       40832.0   \n",
       "7               0.5   35.0  1.066967        319.0       40832.0   \n",
       "8               0.5   40.0  0.975683        319.0       40832.0   \n",
       "9               0.5   45.0  0.883329        319.0       40832.0   \n",
       "10              0.5   50.0  0.911535        319.0       40832.0   \n",
       "11              0.5   55.0  0.906354        319.0       40832.0   \n",
       "12              0.5   60.0  0.800854        319.0       40832.0   \n",
       "13              0.5   65.0  0.854340        319.0       40832.0   \n",
       "14              0.5   70.0  0.874084        319.0       40832.0   \n",
       "15              0.5   75.0  0.762879        319.0       40832.0   \n",
       "16              0.5   80.0  0.709827        319.0       40832.0   \n",
       "17              0.5   85.0  0.773453        319.0       40832.0   \n",
       "18              0.5   90.0  0.744702        319.0       40832.0   \n",
       "19              0.5   95.0  0.707833        319.0       40832.0   \n",
       "20              0.5  100.0  0.724334        319.0       40832.0   \n",
       "\n",
       "    sparse_categorical_accuracy  \n",
       "0                      0.086501  \n",
       "1                      0.269323  \n",
       "2                      0.315904  \n",
       "3                      0.471738  \n",
       "4                      0.644005  \n",
       "5                      0.638911  \n",
       "6                      0.667908  \n",
       "7                      0.681818  \n",
       "8                      0.697002  \n",
       "9                      0.726734  \n",
       "10                     0.714121  \n",
       "11                     0.708758  \n",
       "12                     0.745273  \n",
       "13                     0.730971  \n",
       "14                     0.726318  \n",
       "15                     0.764229  \n",
       "16                     0.780368  \n",
       "17                     0.756294  \n",
       "18                     0.766066  \n",
       "19                     0.775838  \n",
       "20                     0.774882  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_A_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def make_plot(data_frame):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    dff = data_frame.rename(\n",
    "        columns={'sparse_categorical_accuracy': 'Accuracy', 'loss': 'Loss'})\n",
    "\n",
    "    plt.subplot(121)\n",
    "    sns.lineplot(data=dff, x='Round', y='Accuracy', hue='NoiseMultiplier', palette='dark')\n",
    "    plt.subplot(122)\n",
    "    sns.lineplot(data=dff, x='Round', y='Loss', hue='NoiseMultiplier', palette='dark')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAE9CAYAAABZZMC4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABdiUlEQVR4nO3dd3gUZdvG4d+dAgm99957DYj0JsWCqIAgINgQFZXvtfu+9oK9IYqogBUUREDpvYuAIl0IoffeS8rz/ZEVAwQIkM0k2es8jhzZmZ2dvTKsztw7TzHnHCIiIiIiIpL2BXkdQERERERERJKHCjwREREREZF0QgWeiIiIiIhIOqECT0REREREJJ1QgSciIiIiIpJOqMATERERERFJJ0K8DnC58uTJ40qUKOF1DBERSQFLlizZ65zL63WOtELnSBGRwHCx82OaK/BKlCjB4sWLvY4hIiIpwMw2eZ0hLdE5UkQkMFzs/OjXJppm1sbM/jazSDN7OpHni5nZDDP708yWmdn1/swjIiIiIiKSnvmtwDOzYGAA0BaoBHQxs0rnbPY/4EfnXE2gM/CJv/KIiIiIiIikd/68g1cXiHTORTnnTgPDgZvP2cYB2XyPswPb/ZhHREREREQkXfNnH7zCwJYEy1uBa87Z5kVgspk9DGQGWia2IzPrBfQCKFas2HnPR0dHs3XrVk6ePHn1qQNYWFgYRYoUITQ01OsoIiIiIpKG6fo8eVzJ9bnXg6x0AYY65941s2uBb8ysinMuLuFGzrlBwCCAiIgId+5Otm7dStasWSlRogRmliLB0xvnHPv27WPr1q2ULFnS6zgiIiIikobp+vzqXen1uT+baG4DiiZYLuJbl9A9wI8AzrkFQBiQ53Lf6OTJk+TOnVsfnqtgZuTOnVvfsoiIiIjIVdP1+dW70utzfxZ4i4CyZlbSzDIQP4jK2HO22Qy0ADCzisQXeHuu5M304bl6OoYiIiIiklx0bXn1ruQY+q3Ac87FAH2AScBq4kfLXGlmL5tZO99mjwH3mdlfwDCgp3PuvCaYV8LMeOyxx84sv/POO7z44osXfc3AgQP5+uuvL/u9Zs6ciZnxxRdfnFm3dOlSzIx33nnnkq+98cYbzzyeP3/+ZeUZOnQoffr0uar8IiIiIiL+puvzlOHXPnjOufHA+HPWPZ/g8SqggT/eO2PGjIwaNYpnnnmGPHmS1uqzd+/eV/x+VapU4ccff+Tee+8FYNiwYVSvXv2y9jFz5kyyZMlC/fr1ryjP5W4fExNDSIjX3TBFREREJBDo+vzSkuP63K8TnXspJCSEXr168f7775/33MaNG2nevDnVqlWjRYsWbN68GYAXX3zxTEX/0UcfUalSJapVq0bnzp0BOHbsGHfffTd169alZs2ajBkz5sw+ixcvzsmTJ9m1axfOOSZOnEjbtm3PPN+0aVMWL14MwN69eylRosR5mQYOHMj7779PjRo1mDNnzll5mjZtyqOPPkqNGjWoUqUKv//++3l/V8Lt169fT5s2bahduzaNGjVizZo1APTs2ZPevXtzzTXX8OSTT17RsRWReLGxccz+bSNzf99EMjU+EPHU5FmRzFm4yesYIpJO6fo8Za7P0/Xtm4ceeohq1aqdd6AefvhhevToQY8ePRg8eDCPPPIIo0ePPmubN954gw0bNpAxY0YOHjwIwGuvvUbz5s0ZPHgwBw8epG7durRs+e/MDh06dGDEiBHUrFmTWrVqkTFjxiRnLVGiBL179yZLliw8/vjjAEybNu2sbY4fP87SpUuZPXs2d999NytWrLjg/nr16sXAgQMpW7YsCxcu5MEHH2T69OlA/KhG8+fPJzg4OMn5RCRebGwcsxduYsSvKxk1cTW79hwDoH5EUZ5/tAmtmpRWnwNJk6KjY+nz3Hji4hzLpzxIeLimzBGR5Kfrc/9fn6frAi9btmzceeedfPTRR4SHh59Zv2DBAkaNGgVA9+7dE62Uq1WrRteuXWnfvj3t27cHYPLkyYwdO/ZMFX7y5Mkz3y4AdOrUidtvv501a9bQpUuXs9rrJocuXboA0LhxYw4fPnzmg32uo0ePMn/+fDp27Hhm3alTp8487tixo4o7kcsQExPrK+pWMWrianbvPUam8FBuaFGWjjdUZu/+4/QbMIc23b/lmpqFeeH/mtKmaZk0Ueg559i+8wiLl21nyfLtLFm+gwOHThAaEkxoaFD875AgQkMv8Dvhdgl+ZwgNpu+913r958llCA0N5rM3bqL57V/x0gczeeOZ67yOJCLpkK7P/X99nq4LPIC+fftSq1Yt7rrrrst63bhx45g9eza//PILr732GsuXL8c5x08//UT58uXP2nbXrl0AFChQgNDQUKZMmcKHH3541gcoJCSEuLj46f2udCqCcy8WL3TxGBcXR44cOVi6dGmiz2fOnPmK3l8kkMTExDLrt02MGLeSURNWs2ffcTKFh3Jji3J0vLESbZuVJXOmDGe2v/v2mnw1cimvfzyH6+/8jro1CvN83yZc37xsqir0tu887CvmdrBk+XYWL9t+5i5kUJBRuVxe8ufNQnR0LCdOxnA4+hTRMXFER8fG/46JJTo68d+xsf82Uw0ONhV4aVCz+iW5+/aavPPZfDq3q0KNygW9jiQi6ZCuz8+XnNfn6b7Ay5UrF506deLLL7/k7rvvBqB+/foMHz6c7t27891339GoUaOzXhMXF8eWLVto1qwZDRs2ZPjw4Rw9epTWrVvTv39/+vfvj5nx559/UrNmzbNe+/LLL7N79+7zKvASJUqwZMkS6taty8iRIxPNmjVrVg4fPnzBv+WHH36gWbNmzJ07l+zZs5M9e/ZEt8uWLRslS5ZkxIgRdOzYEeccy5Ytu+xOpSKBJiYmlpkLNjJi3Cp+nnh2Udfppsq0bVaGTOEZEn1txowh9OoaQc+ONfj6p794rf8cbuz5PRHVCvF83ybc2LJcihd6O3YdOVPELVm+g8XLtrNz91EgvpirWCYPbZqUoXa1QkRUK0T1Svkv+PclRVxcHDExcZyOji/6JG16+7/X8eu0tdz35C/8NvZegoPTbXd9EfGIrs/9e32e7gs8gMcee4yPP/74zHL//v256667ePvtt8mbNy9Dhgw5a/vY2Fi6devGoUOHcM7xyCOPkCNHDp577jn69u1LtWrViIuLo2TJkvz6669nvfafEXbO9fjjj9OpUycGDRrEDTfckOg2N910Ex06dGDMmDH079//vOfDwsKoWbMm0dHRDB48+KJ/83fffccDDzzAq6++SnR0NJ07d1aBJ5KImJhYZszfyIhxK/l54hr27j9O5kz/3Km7eFGXmAwZQri3S216dKjBN75Cr93dw6hZpQDPP9qEm1tX8Euht2vP0TPNLBf/FV/Qbd91BAAzqFg2L9c1KkVEtULUrlqIGpULnHUHMjkEBQWRIUMQGTIExKkl3cqVMxMfvdSWzg+NpP+QhboTKyJ+oetz/12fW1ob+S0iIsL9M9rNP1avXk3FihU9SpQymjZtyjvvvENERIRf3ycQjqUIwLHjp/nfW9P59udlZ4q6m1qWp+ONlWjT9PKKuouJjo7lu5+X8epHs1m/6QDVK+Xn+b5NaN+6AkFBV3ZnZPfeo/F35P7afuYO3bad/xZz5Uvn8RVyBYmoFl/MZcmc9E7lqYmZLXHO+fd/fOlIYufIK+Gc48ae3zPrt42snPYQxYvkuPpwIhJQAuGa0svr84udH/U1q4gEnHUb9nHrfT+wcu1ubr+pCp1urEybpmX8MmpgaGgwPTvVpNut1Rg2ZgWvfjSb23r9SNUK+Xi+bxNubVvxooXenn3HWJKgieWS5dvZsv3fpiLlSuWmSb0S1K5akNpVC1GrakGyZkmbxZykHmbGp6/fQKXmA3jg2V8Z91XXVNWXVERELkwFXhoxc+ZMryOIpAtjJq3hzv/7mZDgICZ+041WTcqkyPuGhATT/bbq3NG+KsPHruCVD2fRsfcIKpfLy3OPNqHDDZU4ePjkWcXc4mXb2bzt0Jl9lC2ZiwYRxeLvzlUrSM3KBcmeLSxF8kvgKVY4B6892YK+L05k+JgVdGlf1etIIiKpSmq9PleBJyIBITY2juffmcHrH88holohRn7WyZNmZ8HBQXS9pRqd21Xhx19W8spHs+j80EiyP5ORQ4f/HS65dPGcXFurCH161iWiWiFqVi5AjuzhF9mzSPLr07Mu349ezqMvTqBVk9LkzpnJ60giInIJKvBEJN3bu/8Yd/T5iSlzori3Sy36v9yWsDBvJ3EODg6iS/uqdLqpMiPHrWLCjHVUKpc3vplllYLkzKFiTrwXHBzE52/dRO3rB/H4K5MZ8l57ryOJiMglqMATkXRt0dJtdOj9I7v2HuXzt27i3i61vY50luDgIG5vV4Xb21XxOopIoqpVLMAT99en34C5dLu1Gi0alvI6koiIXIQmtxGRdMk5x+ffL6HhbYMxg3mj7kl1xZ1IWvHco00oUyIX9z/9CydORHsdR0RELkIFXioxceJEypcvT5kyZXjjjTfOe37o0KHkzZuXGjVqUKNGDb744gsPUkog27T1IDf0+I6mHYfw9sB5rFq7m9Q6zcqJE9Hc+8RYej31C82uLcGS8fdTu1ohr2OJpFnh4aF89saNrN90gJc/nOV1HBGRFJFWr8/VRDMViI2N5aGHHmLKlCkUKVKEOnXq0K5dOypVqnTWdrfffvtZE0KKpJRfp/7NnX1/JiY2jpJFc/Lka1N48rUplCyWgxual+PGFuVoUq+45/3aADZsPsBt9//Anyt28tyjjXnh/5oSHKzvskSuVvMGpbirUw3eHjiPzu2qUL1SAa8jiYj4TVq+PtdVTyrw+++/U6ZMGUqVKkWGDBno3LkzY8aM8TqWCNHRsTzx6mRuumsYxYvk4I/x9/PX5AfYvPD/GNjvRiqXy8eXw/+gTfdvyV3tLW6+exiff7+EbTsOX3rnfjBhxjpqX/8ZUZsP8MuQLrz8eHMVdyLJ6J3/tSJ3zkzc9+RYYmPjvI4jIuI3afn6XFc+qcC2bdsoWrTomeUiRYqwbdu287b76aefqFatGh06dGDLli0pGVEC0Jbth2jScQjvfDafB7pHsGD0PZQpmRuAooWyc3+3CH4Zcgf7lj3F+K+70rNjDf5avZNeT/1CkbrvUavtQJ57ezq//bHF7xeCcXFxvPzBTG7o8R3FCmdnybj7ubFleb++p0ggypUzEx++2IZFf22n/5CFXscREfGbtHx9riaaCfR9cQJLV+5M1n3WqFyAD15se9X7uemmm+jSpQsZM2bks88+o0ePHkyfPj0ZEoqcb/z0tXR/9GeiY2IZPqDDRUd4DA8PpW2zsrRtVpaP3fWs/Hs346avY9y0tbz+8Rxe/Wg2eXNnom2zstzYohytGpdO1sm5Dxw8QbdHRzF++jq631aNgf1uJFN4hmTbv4ic7fZ2Vfhm1DL+9/Z0bmlT0ZP5JEUksKTWa/TUen2uAi8VKFy48FkV/9atWylcuPBZ2+TOnfvM43vvvZcnn3wyxfJJ4IiOjuW5d6bz5ifzqF4pPyMGdqJsydyXfqGPmVGlQn6qVMjPUw82ZP+B40yatZ5x09fy69S1fD3yL0JCgqhZuQCFC2SjYL4sFMiXhYL5slIgb5Yzy/nzZCE0NPiS7/fnih3cdv8PbN1xmE9eu4He3SMws6s5BCJyCWbGp6/fQKXmA3jg2V8Z91VX/XcnIulOWr4+V4GXQHLcabsSderUYd26dWzYsIHChQszfPhwvv/++7O22bFjBwULFgRg7NixVKxY0Yuocpm2bD/E3v3HqVYxf6rvC7Z1xyE6PzSSeYu2cH+32nzwQpurHjQlV85MdGlflS7tqxITE8vCP7fx67S1LF62nciN+5m7aDN79x9P9LV5cmWKL/jyZqFg/gQFYN74gvDvqL08+sJEcucMZ/bIu6hXq2ii+xHxipkVBb4G8gMOGOSc+/CcbboCTwEGHAEecM795Xtuo29dLBDjnItIufQXV6xwDl57sgV9X5zI8DEr6NK+qteRRCQd8+IaPS1fn6vASwVCQkL4+OOPad26NbGxsdx9991UrlyZ559/noiICNq1a8dHH33E2LFjCQkJIVeuXAwdOtTr2HIRJ09G02/AXN74ZC6nT8eSM3sYTa8tQYsGpWjeoCQVyuRJVd94T5ixju6PjuLU6Vi+73+bXy7WQkKCaVCnGA3qFDtr/enTMezed4wdu46yY/cRdu45yo7dR9m5+9/lv6P2sXPPUU6fjj3rtc3ql2D4gA7ky5Ml2fOKJIMY4DHn3B9mlhVYYmZTnHOrEmyzAWjinDtgZm2BQcA1CZ5v5pzbm4KZk6xPz7p89/MyHn1xAq2blCZXzkxeRxIRSTZp+frcUus8VhcSERHhFi9efNa61atXp5qKOa3Tsbx6E2eso89z41m/6QB3tK9K6yalmblgI9PmbWDztkMAFMqfleYNStK8fklaNCxJscI5PMkaExPLc+/M4I0Bc6lWMT8/ftqR8qXzeJLlUpxzHDh44kwBeOp0DK0alyYk5NJNOSXtMrMlqenO1dUwszHAx865KRd4PiewwjlX2Le8EYi4nAIvsXOkP/21aie1r/+MO2+rzuB326fY+4pI6qdryuST2LG82PlRd/BEksm2HYfp+9JERo5bRfnSuZk67E5aNCwFwJ0dauCcI2rTAabNi2L6vA1MmhXJt6OWAVC6eE5aNCxF8/olaVa/RIrckdq24zCdHxrJ3EWb6dU1vklmeLj389hdiJmRK2cmcuXMRKVy+byOI3JZzKwEUBO42NCT9wATEiw7YLKZOeAz59ygC+y7F9ALoFixYolt4jfVKxXgid4NeGPAXLrdWo3mDUql6PuLiMj5VOCJXKWYmFg+GryQF96bSUxMHK8+0ZzH769Pxoxn/+dlZpQukYvSJXLRq2sEzjlWrNnN9PkbmDY3iuFjVzDouyUAVK2Q70xzzib1ipMta/KNOgkwaWYk3R4dxYmT0Xz70a10vaVasu5fRP5lZlmAn4C+zrlEJ4k0s2bEF3gNE6xu6JzbZmb5gClmtsY5N/vc1/oKv0EQfwcv2f+AS3j+0SaMHLeKXk/9wvIpD6bqL4pERAKBCjyRqzB/8WYeeHYcy1bv4vrmZen/cltKFc+VpNeaGVUr5qdqxfw8ek89YmJiWbJ8B9PnbWDavCgGfruYD778jeBgo1rF/JQokoOihbJTpGA2ihTIRtFC2ShSMBuF8mclQ4ak/accExPLC+/O5PWP51C1Qj5GDOyUaptkiqQHZhZKfHH3nXNu1AW2qQZ8AbR1zu37Z71zbpvv924z+xmoC5xX4HktPDyUz964kRadv+blD2fR7+mWXkcSEQlo6abAc86lqkEr0qK01h/TS/sOHOfpflP5YtgfFCmYjVGDbqd9mwpX9RkMCQnmmppFuKZmEZ7p04iTJ6NZ8MdWps/bwO9Lt/F31D6mzdvA4SOnzntt/ryZKVrQV/z5foomeFy4QDb2HThOlz4/MXvhJu7tUosPX2qj+eJE/Mji/4fwJbDaOffeBbYpBowCujvn1iZYnxkIcs4d8T1uBbycArGvSPMGpbirUw3eHjiPzu2qUL1SAa8jiUgqoOvzq3cl1+d+LfDMrA3wIRAMfOGce+Oc598HmvkWMwH5nHM5Lvd9wsLC2LdvH7lz59aH6Ao559i3bx9hYcnbFDC9iYuLY+iPS3ny9SkcOnKKJ3rX5/m+TciSOWOyv1dYWCjN6pekWf2SZ60/fOQkW3ccPvOzJcHjyI37mbFgA4cOn18EhoYGERoSzDcf3kK3W6sne14ROU8DoDuw3MyW+tY9CxQDcM4NBJ4HcgOf+M5f/0yHkB/42bcuBPjeOTcxRdNfprf/14pfp63lvifHsmDMval+ahgR8S9dn1+9K70+99sommYWDKwFrgO2AouALucMD51w+4eBms65uy+238RGCIuOjmbr1q2cPHkyWbIHqrCwMIoUKUJoqPpPJGb56l088N9fmbdoCw3rFOPT12+gSoX8XsdK1JGjp9i28zBbtv9b/B04dIL77qhNxbJ5vY4nkmTpaRTNlJDSo2iea9jo5dzx8E988GIbHr2nnmc5RMR7uj5PHhe6PvdqFM26QKRzLsoXYjhwM5BogQd0AV64kjcKDQ2lZMmSl95Q5AocPXaKF9+byQdf/kbO7OEMefdm7uxQnaCg1PvtdNYsGalQJi8VyqiYE5GU0/nmKnz78zKe7jeV6pXy0/RanZtFApWuz73jzyvUwsCWBMtbfevOY2bFgZLAdD/mEbkszjlGTVhFxWYDeHfQAu6+vSZrZvahZ6eaqbq4ExHxipnx1fvtKVU8Jzf2/J4FS7Zc+kUiIpKsUstVamdgpHMuNrEnzayXmS02s8V79uxJ4WgSaPYfOM43P/1Fq67fcFuvH8mdM5wFY+5h0JvtyJ0zk9fxRERStTy5MjP1+zspmC8rbe/8lj+Wb/c6kohIQPFnE81tQNEEy0V86xLTGXjoQjvyeo4fSf82bzvImMl/M3rSGmb9tpHYWEfhAll5/4XW9OlZl5CQYK8jioikGQXzZ2Xa8Dtp3GEIrbp+w8wfe6baPssiIumNPwu8RUBZMytJfGHXGbjj3I3MrAKQE1jgxywiZ/lnkvHRk9YwevIa/li+A4BK5fLy1AMNuaVNBWpXK6RRn0RErlCxwjmYNqwHjTsMoeUdXzN75F2UK6V5N0VE/M1vBZ5zLsbM+gCTiJ8mYbBzbqWZvQwsds6N9W3aGRjuNAmb+FlsbBzzF2+JL+omrSFq8wHM4NraRXnrv9dxc6vyuvgQEUlGpUvkOnMnr0Xn+CKvZLGcXscSEUnX/DZNgr94PQS0pC0nTkQzdW4UoyetYeyUv9m7/zgZMgTTsmEp2reuwE0ty1EgX1avY4rIBWiahMuTWs+Ry1bvpGnHoeTIHsbskXdRpGB2ryOJiKRpXk2TIOKJvfuPMWFGJKMnrWHizEiOn4gme7aM3NC8HO1bV6BN0zJkzZL8E5OLiEjiqlUswOTvutOiy9dn7uTlz5vF61giIumSCjxJ8+Li4lj813bGz1jHhBmRLPprG85BofxZ6dmxBu1bV6BJveJkyKCPu4iIVyKqF2b8V11p1fUbWnb5mpkjempkYhERP9AVr6RJe/cfY/Ks9YyfsY5Js9azd/9xzOCamkV48T9Nadu0LLWrFdR8dSIiqUiDOsX4ZUgXru/xHa26fsO0YXeSI3u417FERNIVFXiSJsTFxbFk2Q7fXbp1/L40/i5dnlyZaNO0DG2blqFVk9LkyZXZ66giInIRzRuUYtSg22l/73Cu7/Edk7/rTpbMajYvIpJcVOBJqrXvwPEEd+ki2bMv/i5dneqFeeH/mtK2aRlqVytEcLDu0omIpCXXNy/H8AEd6PTACG66axjjvrqDTOEZvI4lIpIuqMCTVGXjlgN889Myxvvu0sXFOXLnDKd1kzJc37wsrRqXJm9u3aUTEUnrbm1bia/fv4Vuj47i1vt+YMyXXciYUZclIiJXS/8nlVThxIlo3vhkLm9+OpdTp2KpU70Q/3ukMdc3L0uE7tKJiKRLd9xSjZOnYrjnibHc/uAIRgzsRGhosNexRETSNBV44innHGMn/03flyaycctBOrerwlv/vY6ihTRHkohIILi7cy2On4zm4ecm0P3RUXzX/zZ9qScichVU4Iln1m3Yx6MvTGDCjEgqlcvL9B960Kx+Sa9jiYhICuvT8xpOnIzhydemEB4WypfvtNMoyCIiV0gFnqS4Y8dP83r/ObwzaD4ZMwTz3vOt6dOzrprliIgEsCd6N+D4iWhefG8m4WEhDHjtBszM61giImmOCjxJMc45Rk1YzX9ensTmbYfodms13nr2Ogrmz+p1NBERSQWe79uEY8dP8/bA+YSHhfLOc61U5ImIXCYVeJIi/l6/l4efG8+UOVFUq5ifbz+8lUbXFPc6loiIpCJmxpvPXseJkzG89/kCalYpQLdbq3sdS0QkTVEDd/Gro8dO8XS/KVS97hN+/2sbH73cliXje6m4ExGRRJkZH77Uhro1CvPYK5M5cPCE15FERNIUFXjiF845fvxlBRWafsybn8yja/tq/D3zYR6+6xpCQtTXTkRELiwoKIiB/W5k7/7j/PetaV7HERFJU9REU9i15yi39vqBjBmCKVwgG4XyZ6VwgawULpDtzO8CebMkeRCUVWt38/DzE5g+bwM1qxRgxMBOXFu7qJ//ChERSU9qVinIw3fV5aPBC+nZsQZ1axbxOpKISJqgAk/4eeJq5i/eQt0ahZnz+ya27zpCdHTcWduYQf68WSicP6uvAMx2XhGYM3sY732+gA8HLyRr5gx88toN9OpaW/MZiYjIFXn5sWaM+HUVvZ/9ld9/uU8tQEREkkAFnjBxZiTFi2Tnt7H3YmbExcWx78AJtu08zLadR8783r4r/vGmbYeYv2QL+w6c3y/CDO7pXIvXn2pB3tyZPfhrREQkvciWNYwPXmxDpwdG8MnXi3jk7npeRxIRSfVU4AW406djmDZvA11vqXpmKOqgoCDy5s5M3tyZqVG54AVfe/JkNNt3/VP4HWHH7iM0rFOMiOqFUyq+iIikcx1uqETrJqX539vT6XB9JQoVyOZ1JBGRVE0FXoCbv2QLR4+dpm3Tspf92rCwUEoVz0Wp4rn8kExERCR+VM2PX7meKtd9wv+9NIkfPu3odSQRkVRNnaMC3MSZkYSEBNG8QUmvo4iIiCSqTMnc/LdPY378dSWTZ0V6HUdEJFVTgRfgJs6MpGGdYmTNktHrKCIi6YqZFTWzGWa2ysxWmtmjiWxjZvaRmUWa2TIzq5XguR5mts730yNl06c+Tz7QgHKlcvPgf8dx4kS013FERFItFXgBbPvOw/y1ahdtmpbxOoqISHoUAzzmnKsE1AMeMrNK52zTFijr++kFfApgZrmAF4BrgLrAC2aWM6WCp0YZM4bwyWs3sH7TAd74ZK7XcUREUi0VeAFs0qz1ACrwRET8wDm3wzn3h+/xEWA1cO4oVDcDX7t4vwE5zKwg0BqY4pzb75w7AEwB2qRg/FSpRcNS3NG+Km98Mpe1UXu9jiMikiqpwAtgE2dGUjBfFqpVzO91FBGRdM3MSgA1gYXnPFUY2JJgeatv3YXWB7x3n2tFeFgID/1vPM45r+OIiKQ6KvACVExMLFPmrKdN0zJnpkcQEZHkZ2ZZgJ+Avs65w37Yfy8zW2xmi/fs2ZPcu091CuTLymtPtGDqnCiGj1nhdRwRkVRHBV6AWvTXdg4cOqnmmSIifmRmocQXd98550Ylssk2oGiC5SK+dRdafx7n3CDnXIRzLiJv3rzJEzyV6909gohqhfjPK5M4dPik13FERFIVFXgBauLMSIKCjJYNS3kdRUQkXbL45hFfAqudc+9dYLOxwJ2+0TTrAYecczuASUArM8vpG1yllW+dAMHBQQzsdyO79x7jf29P9zqOiEiq4tcCz8zamNnfvuGfn77ANp0SDCH9vT/zyL8mzozkmpqFyZUzk9dRRETSqwZAd6C5mS31/VxvZr3NrLdvm/FAFBAJfA48COCc2w+8Aizy/bzsWyc+tasV4sE76/DJ14tY/FeiNzdFRAJSiL92bGbBwADgOuI7hy8ys7HOuVUJtikLPAM0cM4dMLN8/soj/9qz7xiL/trGi/9p6nUUEZF0yzk3F7hoJ2cXP0rIQxd4bjAw2A/R0o1Xn2jOyPGr6P3Mryz85T6Cg9UwSUTEn/8nrAtEOueinHOngeHEDwed0H3AAN8Q0Djndvsxj/hMmb0e56BNE/W/ExGRtCt7tjDef741S5bvYOA3i72OIyKSKvizwEvKEM/lgHJmNs/MfjOzgJ/jJyVMnBVJnlyZiKheyOsoIiIiV+X2dlVo2agUz741jZ27j3gdR0TEc163ZQgBygJNgS7A52aW49yNAm0IaH+Ki4tj0qz1tGpcmqAgr//5RUREro6Z8clrN3DqdAz/eVnj0IiI+PMKPylDPG8Fxjrnop1zG4C1xBd8ZwnEIaD9ZenKnezee0zTI4iISLpRtmRunn6wIcPGrGDqnPVexxER8ZQ/C7xFQFkzK2lmGYDOxA8HndBo4u/eYWZ5iG+yGeXHTAFv4sxIAFo1Lu1xEhERkeTz9IMNKVMiFw/+dxwnT0Z7HUdExDN+K/CcczFAH+Ln7VkN/OicW2lmL5tZO99mk4B9ZrYKmAE84Zzb569MAhNmRFKrakHy583idRQREZFkExYWyoBXr2fdhv28NXCe13FERDzj105YzrnxzrlyzrnSzrnXfOued86N9T12zrn/OOcqOeeqOueG+zNPoDt46AQL/tii0TNFRCRdatWkDLffVJnXP55D5AZ9XywigUmjbASQafM2EBvraNtMBZ6IiKRP7z3fmgyhwfR5bjzx0wyKiAQWFXgBZOLMSLJny0i9WkW8jiIiIuIXhQpk47UnWzBp1npGjlvldRwRkRSnAi9AOOeYODOSlg1LERIS7HUcERERv3nwzjrUqlqQR1+YwOEjJ72OIyKSolTgBYhVa/ewdcdhTY8gIiLpXnBwEANfv5Gde47y+sdzvI4jIpKiVOAFiAkz1gHQWgOsiIhIAKhTozBdbq7KgK8Wse/Aca/jiIikGBV4AWLirEgql8tL0ULZvY4iIiKSIp7t04ijx07z0eCFXkcREUkxKvACwNFjp5jz+2baNivrdRQREZEUU7l8Pm5pU4GPhixUXzwRCRgq8ALAzAUbOX06Vv3vREQk4Pz34cYcPHSST75e5HUUEZEUoQIvAEycGUmm8FAa1inmdRQREZEUVbtaIdo0LcN7ny/g+InTXscREfE7FXgBYOLMSJo3KEnGjCFeRxEREUlx/3ukMXv2Hefz7//wOoqIiN+pwEvnIjfsY/2mA7TR6JkiIhKgGtQpRpN6xXl74DxOnYrxOo6IiF+pwEvnJsyMBFD/OxERCWj/e6Qx23Ye4auRS72OIiLiVyrw0rmJMyMpWzIXpUvk8jqKiIiIZ1o0LEXdGoV545O5xMTEeh1HRMRvVOClYydPRjNj/gbdvRMRkYBnZvz34UZs2HyQYWNWeB1HRMRvVOClY3N+38yJkzEq8ERERIAbW5ajWsX8vP7xHOLi4ryOIyLiFyrw0rGJMyPJmDGYJvVKeB1FRETEc0FBQTzbpxFrIvcyasJqr+OIiPiFCrx0bOKsSBrXLU7mTBm8jiIiIpIqdLihEuVK5ea1/nNwznkdR0Qk2anAS6c2bzvIqrV71DxTREQkgeDgIJ55qCFLV+5k/PR1XscREUl2KvDSqYm+6RHaNivrcRIREZHUpest1SheJDuvfjRbd/FEJN1RgZdOTZwZSbHC2alQJo/XUURERFKV0NBgnnqgIb/9sZUZ8zd4HUdEJFmpwEuHoqNjmTo3ijZNy2BmXscRERFJde7qVIOC+bLwWv85XkcREUlWKvDSoQVLtnDk6GnaNFH/OxERr5jZYDPbbWaJTrpmZk+Y2VLfzwozizWzXL7nNprZct9zi1M2eWAICwvl8fvrM33eBhYs2eJ1HBGRZKMCLx2aODOSkJAgWjQs6XUUEZFANhRoc6EnnXNvO+dqOOdqAM8As5xz+xNs0sz3fIR/Ywau+7tFkDtnOK/1n+11FBGRZKMCLx2aMDOSBhFFyZY1zOsoIiIByzk3G9h/yQ3jdQGG+TGOJCJzpgz8373XMm7aOv5cscPrOCIiyUIFXjqzY9cRlq7cqekRRETSCDPLRPydvp8SrHbAZDNbYma9vEkWGPr0rEv2bBl5/WP1xROR9EEFXjozefZ6ABV4IiJpx03AvHOaZzZ0ztUC2gIPmVnjC73YzHqZ2WIzW7xnzx5/Z013smcLo0+Puvw0fhWr1+n4iUja59cCz8zamNnfZhZpZk8n8nxPM9uToJP5vf7MEwgmzoykQL4sVK9UwOsoIiKSNJ05p3mmc26b7/du4Geg7oVe7Jwb5JyLcM5F5M2b169B06u+99YjPCyUfgN0F09E0j6/FXhmFgwMIP7bx0pAFzOrlMimP/zTydw594W/8gSC2Ng4Js9eT+vGpTU9gohIGmBm2YEmwJgE6zKbWdZ/HgOtgERH4pTkkSdXZnp3i+D70cuJ2pTUbpMiIqmTP+/g1QUinXNRzrnTwHDgZj++X8BbvGw7+w+eUPNMEZFUwMyGAQuA8ma21czuMbPeZtY7wWa3AJOdc8cSrMsPzDWzv4DfgXHOuYkplzwwPdbrWkJCgnjz03leRxERuSohftx3YSDhxDJbgWsS2e42X9+CtcD/Oec0Gc0VmjBjHUFBxnWNS3sdRUQk4DnnuiRhm6HET6eQcF0UUN0/qeRCChXIxt2davLF8D947tHGFCmY3etIIiJXxOtBVn4BSjjnqgFTgK8S20gdyJNm4sxI6tYoTO6cmbyOIiIikuY8+UADnIN3PpvvdRQRkSvmzwJvG1A0wXIR37oznHP7nHOnfItfALUT25E6kF/avgPH+X3pNjXPFBERuUIliuak2y3VGPTdEnbvPep1HBGRK+LPAm8RUNbMSppZBuJHCRubcAMzK5hgsR2w2o950rUps9fjnKZHEBERuRrP9GnIyVMxvP/Fb15HERG5Ipcs8MzsJjO77ELQORcD9AEmEV+4/eicW2lmL5tZO99mj5jZSl9H8keAnpf7PhJv4sxIcuUIJ6JaIa+jiIiIpFnlSuWh042VGfDV7xw4eMLrOCIily0phdvtwDoze8vMKlzOzp1z451z5ZxzpZ1zr/nWPe+cG+t7/IxzrrJzrrpzrplzbs3l/wkSFxfHxFmRtGpcmuBgr7tVioiIpG3PPtyII0dP03/oQq+jiIhctktWA865bkBNYD0w1MwW+AY9yer3dJIky1bvYteeY7RtpuaZIiIiV6taxQK0u648H3zxG0eOnrr0C0REUpEk3e5xzh0GRhI/l11B4uft+cPMHvZjNkmiCTMiAWil6RFERESSxX8fbsSBQycZ+O1ir6OIiFyWpPTBa2dmPwMzgVCgrnOuLfFz9Dzm33iSFBNnRlKzSgEK5NNNVRERkeRQt2YRrmtUincHzefEiWiv44iIJFlS7uDdBrzvnKvqnHvbObcbwDl3HLjHr+nkkg4dPsn8JVto00TNM0VERJLTfx9uzK49x/jyhz+8jiIikmRJKfBeBH7/Z8HMws2sBIBzbpp/YklSTZ+3gZiYOE2PICIikswa1ytOwzrFeGPAXN3FE5E0IykF3gggLsFyrG+dpAK/TltL9mwZubZ20UtvLCIiIklmZrz6RHO27TyiETVFJM1ISoEX4pw7/c+C73EG/0WSpIqNjeOXqX9zfbOyhIYGex1HREQk3WlybQluaFGWfgPmsv/Aca/jiIhcUlIKvD0JJibHzG4G9vovkiTVgiVb2LPvOO1bX9b0hCIiInIZ+j3VkkOHT/LGJ3O9jiIicklJKfB6A8+a2WYz2wI8Bdzv31iSFKMnrSFDhmD1vxMREfGjqhXzc+dt1floyEK2bD/kdRwRkYtKykTn651z9YBKQEXnXH3nXKT/o8nFOOcYPWkNLRqUJFvWMK/jiIiIpGsvP94MgBfeneFxEhGRi0vSROdmdgPwIPAfM3vezJ73byy5lJV/72b9pgPc3ErNM0VE/M3MMptZkO9xOd8csaFe55KUU6xwDvr0qMtXI/9ixZpdXscREbmgpEx0PhC4HXgYMKAjUNzPueQSxkz+G4B215X3OImISECYDYSZWWFgMtAdGOppIklxz/RpRNYsGXj2Tc0SJSKpV1Lu4NV3zt0JHHDOvQRcC5Tzbyy5lNGT1lCvVhEK5s/qdRQRkUBgzrnjwK3AJ865jkBljzNJCsudMxNPPdCQX6auZc7CTV7HERFJVFIKvJO+38fNrBAQDRT0XyS5lC3bD7F42XaNnikiknLMzK4FugLjfOs0P00AevSeayiYLwtP9ZuCc87rOCIi50lKgfeLmeUA3gb+ADYC3/sxk1zCWF/zTBV4IiIppi/wDPCzc26lmZUCNNpGAMoUnoGXHmvGgiVbGTNpjddxRETOc9ECz9ehfJpz7qBz7ifi+95VcM5pkBUPjZ68hvKlc1O+dB6vo4iIBATn3CznXDvn3Ju+c+Ne59wjXucSb9zVqQblS+fmmTenERMT63UcEZGzXLTAc87FAQMSLJ9yzmkCGA8dPHSCmQs26u6diEgKMrPvzSybmWUGVgCrzOwJr3OJN0JCgun3VEvWRO7lq5F/eR1HROQsSWmiOc3MbjMz83sauaTx09cRExOnAk9EJGVVcs4dBtoDE4CSxI+kKQGqfZsK1KtVhBfencHxE6e9jiMickZSCrz7gRHAKTM7bGZHzOywn3PJBYyevIYC+bJQt0Zhr6OIiASSUN+8d+2Bsc65aEAjbAQwM+PNZ1qybecR+g/53es4IiJnXLLAc85ldc4FOecyOOey+ZazpUQ4OdupUzFMmBFJu+vKExSUpDnqRUQkeXxG/CBjmYHZZlYc0JedAa5xvRLc2LIc/QbMYf+B417HEREBkjbReePEflIinJxt+vwNHD12Ws0zRURSmHPuI+dcYefc9S7eJqCZ17nEe/2easHhI6foN2Cu11FERAAIScI2CTuRhwF1gSVAc78kkgsaPWkNWTJnoHn9kl5HEREJKGaWHXgB+OcLzlnAy4AGHgtwVSrkp0eHGvQfupCH76pLscI5vI4kIgEuKU00b0rwcx1QBTjg/2iSUFxcHGMmr+H6ZmXJmDEpdbmIiCSjwcARoJPv5zAwxNNEkmq89FhTAF54d6anOUREIGmDrJxrK1AxuYPIxS38cxu79hxT80wREW+Uds694JyL8v28BJS62AvMbLCZ7TazFRd4vqmZHTKzpb6f5xM818bM/jazSDN7Opn/FklmxQrn4OGe1/DVyKUsX73L6zgiEuCS0gevv5l95Pv5GJgD/OH/aJLQ6ElrCAkJom2zMl5HEREJRCfMrOE/C2bWADhxidcMBdpcYps5zrkavp+XffsOJn4O2rZAJaCLmVW64uSSIp55qCHZsmbk2bemeR1FRAJcUtr6LU7wOAYY5pyb56c8cgFjJq+h2bUlyJE93OsoIiKBqDfwta8vHsR3VehxsRc452abWYkreK+6QKRzLgrAzIYDNwOrrmBfkkJy5czEMw814ul+U5n920Ya1yvhdSQRCVBJaaI5EvjWOfeVc+474Dczy+TnXJLAmsg9/L1+n5pnioh4xDn3l3OuOlANqOacq0nyDDZ2rZn9ZWYTzKyyb11hYEuCbbb61iXKzHqZ2WIzW7xnz55kiCRX6pG7rqFwgaw81W8qzmmaRBHxRlIKvGlAwttG4cDUpOw8qX0IzOw2M3NmFpGU/Qaa0ZPWANCuVXmPk4iIBDbn3GHn3D/z3/3nKnf3B1DcVzj2B0ZfYaZBzrkI51xE3rx5rzKSXI3w8FBeeqwZv/2xldET13gdR0QCVFIKvDDn3NF/FnyPL3kHL6l9CMwsK/AosDCpoQPN6ElriKhWiCIFs196YxERSSl2NS/2FYtHfY/HA6FmlgfYBhRNsGkR3zpJA3p0qE7Fsnl45s2pxMTEeh1HRAJQUgq8Y2ZW658FM6vNpTuWQ4I+BM6508A/fQjO9QrwJnAyCfsMONt3Hmbhn9vUPFNEJPW5qjZ4ZlbAzMz3uC7x5+R9wCKgrJmVNLMMQGdg7NWGlZQREhJMv6da8vf6fQz5canXcUQkACVlkJW+wAgz2078t5UFgNuT8LrE+hBck3ADX+FY1Dk3zswSTqguPr9MXQugAk9ExANmdoTECznj7O4Lib12GNAUyGNmW4mfKD0UwDk3EOgAPGBmMcR/cdrZxXfcijGzPsAkIBgY7JxbmTx/kaSEdq3KUz+iKC+8O4Out1QlU3gGryOJSAC5ZIHnnFtkZhWAfzqA/e2ci77aNzazIOA9oGcStu0F9AIoVqzY1b51mjJ60hrKlMhFpXLqVyEiktKcc1mv4rVdLvH8x8DHF3huPDD+St9bvGVmvPlMSxrdNoQPv1zIM30aeR1JRAJIUubBewjI7Jxb4ZxbAWQxsweTsO9L9SHIClQBZprZRqAeMDaxgVYCtQP54SMnmTYvivatK+BrxSMiIiJpQMO6xWl3XXne/HQu+w4c9zqOiASQpPTBu885d/CfBefcAeC+JLzuon0InHOHnHN5nHMlnHMlgN+Ads65xYnvLvBMmBFJdHQcN2v0TBERkTTn9adacOToafp9PMfrKCISQJJS4AVbgttHvtExL9mY3DkXA/zTh2A18KNzbqWZvWxm7a40cCAZM3kNeXNn4traRS+9sYiIiKQqlcvno0eH6vQf+jubth70Oo6IBIikFHgTgR/MrIWZtQCGAROSsnPn3HjnXDnnXGnn3Gu+dc87584bDcw511R37/51+nQM46avo9115QkOTso/k4iIiKQ2Lz3WDDN44d0ZXkcRkQCRlMrhKWA60Nv3s5xLjBwmV2/mgo0cPnJKo2eKiIikYUULZeeRu67h65/+YuXfu72OIyIB4JIFnnMujvhJyDcSP7ddc+KbXIofjZ60hkzhobRoUMrrKCIiInIVnnqwIZkzZeDVj2Z7HUVEAsAFCzwzK2dmL5jZGqA/sBnAOdfMN7Sz+ElcXBxjJv9Nm6ZlCA8P9TqOiIiIXIXcOTPxcM+6/PDLClat1V08EfGvi93BW0P83bobnXMNnXP9gdiUiRXYlizbwfZdR9Q8U0REJJ34T69ryRQeqrt4IuJ3FyvwbgV2ADPM7HPfACuajC0FjJ60huBg44bmZb2OIiIiIskgT67M9OlZl+FjV7Amco/XcUQkHbtggeecG+2c6wxUAGYAfYF8ZvapmbVKoXwBafTkNTSpV4JcOTN5HUVERESSyWO96hMeFsorH+ounoj4T1IGWTnmnPveOXcTUAT4k/iRNcUP1m3Yx6q1ezS5uYiISDqTN/e/d/H+Xr/X6zgikk5d1gRrzrkDzrlBzrkW/goU6MZMWgPAza3U/05ERCS9efz++oRlDFFfPBHxG82gncqMnryGmlUKULxIDq+jiIiISDLLmzszD95Zh+9HL2dtlO7iiUjyU4GXiuzac5T5i7do9EwREZF07Ine9cmYIVh38UTEL1TgpSK/TP0b59Q8U0REJD3LlycLD95Zh+9+Xs66Dfu8jiMi6YwKvFRk9KQ1lCiag2oV83sdRURERPzoid4NyJghmNd0F09EkpkKvFTi6LFTTJ0bRftWFTDTdIMiIiLpWf68WXigex2+/XkZkbqLJyLJSAVeKjFp1npOnYpV/zsREZEA8UTv+oSGBPNa/zleRxGRdEQFXioxetIacucMp0Gdol5HERERkRRQIF9WeneL4JtRf7F+436v44hIOqECLxWIjo7l12lrubFFOUJCgr2OIyIiIinkyQca+O7iqS+eiCQPFXipwOyFmzh46KSaZ4qIiASYgvmzcn+32nz9019EbdJdPBG5eirwUoExk9cQHhZCqyalvY4iIiIiKezJ3g0ICQni9Y/VF09Erp4KPI855xg9aQ2tGpcmU3gGr+OIiIhICitUIBu97qjNVyP/YsPmA17HEZE0TgWex/5csYMt2w9rcnMREZEA9tQDDQkONt3FE5GrpgLPY6MnrSEoyLixZTmvo4iIiIhHChfMxn1dajN0xFI2btFdPBG5cirwPDZm8t80rFOMvLkzex1FREREPPTUgw0ICjL6DZjrdRQRScNU4HkoatN+lq3epdEzRUREhCIFs3Nv51oM/uFPNm096HUcEUmjVOB5aMzkvwG4uVV5j5OIiEhyM7PBZrbbzFZc4PmuZrbMzJab2Xwzq57guY2+9UvNbHHKpRavPf1QQ99dPPXFE5ErowLPI/sOHGfQ90uoWiEfpYrn8jqOiIgkv6FAm4s8vwFo4pyrCrwCDDrn+WbOuRrOuQg/5ZNUqGih7Nxze00G//Anm7cd9DqOiKRBKvA8sGvPUZp1GsqGLQd453+tvI4jIiJ+4JybDVxw5mrn3Hzn3D+jafwGFEmRYJLqPf1QQwD6fay+eCJy+VTgpbCtOw7RpOMQ1m86wLihXWnVpIzXkURExHv3ABMSLDtgspktMbNeHmUSjxQrnIN7bq/Flz/8wZbth7yOIyJpjF8LPDNrY2Z/m1mkmT2dyPO9E/QxmGtmlfyZx2sbNh+gcYch7Nh9lMnfdadFw1JeRxIREY+ZWTPiC7ynEqxu6JyrBbQFHjKzxhd5fS8zW2xmi/fs2ePntJJSnukTfxfvDY2oKSKXyW8FnpkFAwOIPzlVArokUsB975yr6pyrAbwFvOevPF5bG7WXxh2GcOjwKaYNu5MGdYp5HUlERDxmZtWAL4CbnXP7/lnvnNvm+70b+Bmoe6F9OOcGOecinHMRefPm9XdkSSHFCufgrk41+WL4H2zdobt4IpJ0/ryDVxeIdM5FOedOA8OBmxNu4Jw7nGAxM/FNUtKdFWt20bjDEE5HxzLjxx5EVC/sdSQREfGYmRUDRgHdnXNrE6zPbGZZ/3kMtAISHYlT0rdn+zQiLs7pLp6IXBZ/FniFgS0Jlrf61p3FzB4ys/XE38F7JLEdpeXmJ0uWbadJx6EEBwUxa0RPqlUs4HUkERFJAWY2DFgAlDezrWZ2j69rQm/fJs8DuYFPzpkOIT8w18z+An4HxjnnJqb4HyCeK14kB3d1qsHnw/5g247Dl36BiAipYJAV59wA51xp4vse/O8C26TJ5ifzF2+meeevyJY1I3N+uosKZdJOdhERuTrOuS7OuYLOuVDnXBHn3JfOuYHOuYG+5+91zuX0TYVwZjoEX8uX6r6fys6517z9S8RL/9zFe/NT3cUTkaTxZ4G3DSiaYLmIb92FDAfa+zFPipo+L4pWXb+hQN4szB55l+a6ExERkctWomhOenSozqDvl7B9p+7iicil+bPAWwSUNbOSZpYB6AyMTbiBmZVNsHgDsM6PeVLMhBnruKHH95QsmpNZI3pStFB2ryOJiIhIGvVsn0bExjre/HSe11FEJA3wW4HnnIsB+gCTgNXAj865lWb2spm1823Wx8xWmtlS4D9AD3/lSSk/T1jNzfcMo1K5vMwc0ZMC+bJ6HUlERETSsFLFc3HnbdUZ9J3u4onIpfm1D55zbrxzrpxzrvQ/fQicc88758b6Hj/q619QwznXzDm30p95/O37n5fR8YEfiahWiGnD7iR3zkxeRxIREZF04L8PNyI2Lo7OD43k+InTXscRkVTM80FW0osvh/9Bt0dH0ahucSZ/150c2cO9jiQiIiLpRKniufj2w1uZu2gzt/X6kdOnY7yOJCKplAq8ZNB/yELufWIsrZuUYfxXXcmSOaPXkURERCSd6XRTFQa9eRMTZ0bS7dFRxMbGeR1JRFKhEK8DpHVvfjKXp/tN5ZY2FRj2cQcyZtQhFREREf+4t0ttDh85xWOvTCZbll/4/K12mJnXsUQkFVE1coWcc7z43kxe/mAWXW6uwlfv30JoaLDXsURERCSd+0+v+hw8fJJXPpxN9qxhvPNcKxV5InKGCrwr9HS/qbz16Tzu6VyTz964ieBgtXYVERGRlPHSY804ePgk732+gBzZwniubxOvI4lIKqEC7wqsidzDW5/O4747ajGw340EBam4ExERkZRjZnzwYhsOHznF8+/OIHu2jDxydz2vY4lIKqAC7wpMnRsFwDMPNVJxJyIiIp4ICgrii7fbcfjoKR59YSLZsmSkZ6eaXscSEY+pOrkCU+dEUapYTkoWy+l1FBEREQlgISHBDPu4A9c1KsU9T4xl1IRVXkcSEY+pwLtMMTGxzFiwkZaNSnkdRURERISMGUP4+YvO1KtVhM4PjWTyrEivI4mIh1TgXabFy7Zz+MgpWjZUgSciIiKpQ+ZMGRg39A4qlc3LLff9wPzFm72OJCIeUYF3mabOicIMmtUv4XUUERERkTNyZA9n0rfdKVIwG9f3+I6lK3d4HUlEPKAC7zJNnRtFzSoFyZMrs9dRRERERM6SP28WpnzfnWxZMtKq6zesjdrrdSQRSWEq8C7DseOnmb9ki5pnioiISKpVrHAOpg67E4CWXb5m87aD3gYSkRSlAu8yzFm4iejoOBV4IiIikqqVK5WHyd915/DRU7Ts8jW79hz1OpKIpBAVeJdhypwoMmYMpmGdYl5HEREREbmoGpULMv6rrmzbeYTW3b7hwMETXkcSkRSgAu8yTJ0bRYOIYoSHh3odRUREROSS6kcUY/QXnVkduZcben7HseOnvY4kIn6mAi+Jdu05yrLVu9Q8U0RERNKU6xqXZtjHt7Hwz23ccu9wTp2K8TqSiPiRCrwkmj5vA4AKPBEREUlzbm1bicHv3MyUOVG0u3sY+w8c9zqSiPiJCrwkmjo3ihzZw6hVtaDXUUREREQuW4+ONfjy7XbMWLCBWtd/xpJl272OJCJ+oAIvCZxzTJmznub1SxIcrEMmIiIiadPdnWsx96e7iYtz1L/lSz7/fgnOOa9jiUgyUrWSBJEb97Nl+2E1zxQREZE0r27NIvwx4X6a1itBr6d+4e7HxnD8hAZfEUkvVOAlwdQ5UQC0bKQCT0RERNK+PLkyM/7rrjzftwlDRyylfvsvidywz+tYIpIMVOAlwdS5URQrnJ0yJXJ5HUVEREQkWQQHB/HSY80Y99UdbN52iIgbBzFm0hqvY4nIVVKBdwmxsXFMn7+Blg1LYWZexxERERFJVtc3L8cfE+6nTPFctL93OM+8MZWYmFivY4nIFVKBdwl/LN/BwUMn1f9OREQum5kNNrPdZrbiAs+bmX1kZpFmtszMaiV4roeZrfP99Ei51BKIShTNydxRd9Ora23eGDCXVl2/Ydeeo17HEpEroALvEqbOje9/17xBSY+TiIhIGjQUaHOR59sCZX0/vYBPAcwsF/ACcA1QF3jBzHL6NakEvLCwUD574yaGvHszC5ZspVbbz5i3aLPXsUTkMvm1wDOzNmb2t++byacTef4/ZrbK963lNDMr7s88V2Lq3CiqVcxP/rxZvI4iIiJpjHNuNrD/IpvcDHzt4v0G5DCzgkBrYIpzbr9z7gAwhYsXiiLJpmenmvw29l7Cw0Jo2mkoH375m6ZSEElD/FbgmVkwMID4bycrAV3MrNI5m/0JRDjnqgEjgbf8ledKHD9xmrmLNqt5poiI+EthYEuC5a2+dRdaL5IiqlcqwOJxvbi+WVn6vjiRzg+O5MjRU17HEpEk8OcdvLpApHMuyjl3GhhO/DeVZzjnZjjnjvsWfwOK+DHPZZu3aAunT8dqegQREUm1zKyXmS02s8V79uzxOo6kIzmyh/PzF7fzxjMtGTl+FXVv+pxVa3d7HUtELsGfBd7lfvt4DzDBj3ku29S5UYSGBtGobjGvo4iISPq0DSiaYLmIb92F1p/HOTfIORfhnIvImzev34JKYAoKCuKpBxsyddid7D94gro3fc7wMcu9jiUiF5EqBlkxs25ABPD2BZ735NvJqXOjuLZWUbJkzphi7ykiIgFlLHCnbzTNesAh59wOYBLQysxy+gZXaeVbJ+KJZvVL8sf4+6leqQBd+vzEI8+P5/TpGK9jiUgi/FngJenbRzNrCfwXaOecS7RxtxffTu7df4w/V+xQ/zsREbliZjYMWACUN7OtZnaPmfU2s96+TcYDUUAk8DnwIIBzbj/wCrDI9/Oyb52IZwoXzMbMH3vS95569B/yO81u/4rtOw97HUtEzhHix30vAsqaWUniC7vOwB0JNzCzmsBnQBvnXKpq1D1j/kacQ/3vRETkijnnulzieQc8dIHnBgOD/ZFL5EqFhgbz/ottqFerCPc8MYZa13/Gj590pHG9El5HExEfv93Bc87FAH2Ib1KyGvjRObfSzF42s3a+zd4GsgAjzGypmY31V57LNXVuFFmzZKBO9UJeRxERERFJVW5vV4WFY+8je9Ywmnf+ivc/X6CpFERSCX/ewcM5N5745icJ1z2f4HFLf77/1Zg6J4pm15YkJCTY6ygiIiIiqU7l8vn4/Zf76Pmf0fzn5Uks/HMrX7zdTmMXiHgsVQyyktpEbdpP1OYDap4pIiIichHZs4Ux6vP4qRRGjFtFvXZfsDZqr9exRAKaCrxETJu3AUADrIiIiIhcgpnx1IMNmfRtN3btPUbEDYMYPXG117FEApYKvERMnRNFofxZqVAmj9dRRERERNKElo1Ks2R8LyqUzsMt9/3AM29MJTY2zutYIgFHBd454uLimDYvipaNSmFmXscRERERSTOKFc7BnJ/u5v5utXljwFzadP+WPfuOeR1LJKCowDvHX6t2se/ACTXPFBEREbkCGTOGMLDfTQx+52bm/L6J2td/xqKl502FnCx27z3Khs0H2L33KMdPnNZIniL4eRTNtGjq3CgAWjQo6XESERERkbTrrttrUr1Sfm7t9QMNbxvMx69cz3131L7i/TnnWL9xP3N+38yc3zcx5/fNRG7cf9Y2ZpApPJTMmTKQOVMoWTJlOPM4c7hvXeYMZx5nzpSBLJkzULNyARrWLX61f7JIqqAC7xxT50RRqVxeChXI5nUUERERkTStVtVCLBl/P10f/oleT/3Cwj+38vEr1xMWFnrJ18bFxbF8ze74Ym5hfFG3Y/dRAHLlCKdhnWLc37U2eXJl4ujx0xw7Hs0x3+/45QTrTkSzZ9/xM4+PHT/N0WOnSXjD7/0XWtP33mv9dShEUowKvAROnoxmzu+brurbJRERERH5V+6cmRj3VVdeen8mr3w4m6UrdzLys06UKJrzrO1On45h8bLtZ+7QzV20mUOHTwFQpGA2mtUvSaO6xWhUtzgVy+YhKOjqeho55zh5MobDR0/x4H/H8X8vTWLbziO8+WzLq963iJdU4CWw4I+tnDgZo/53IiIiIskoODiIlx9vTp3qhenedxS1rx/E0PfaE5YxhDm/b2L2wk0s/HMbJ0/FAFChTB463ViZRnWL06huMYoXyZHsg9+ZGeHhoYSHh/Ljpx155PkJvPPZfHbsPsLgd24mQwZdJkvapE9uAlPnRBEcbDSppzbYIiIiIsntpuvKs/jXXtx2/4+0u3sYAEFBRs3KBejdLYJG1xSjYZ1i5MuTJUVzBQcH8fGr11OkYDaefXMau/Ye46fPOpEta1iK5hBJDirwEpg6N4prahbRf8wiIiIiflKmZG4WjLmH70cvp2jB7FxbO3Vce5kZz/RpRKH8WbnniTE06TiU8V91pWD+rF5HuyjnHLv3HmPl2t2sXLuHVWv3UL1Sfu7vFqEpvwKUCjyfAwdPsHjZdv73SGOvo4iIiIika5nCM3Bvl9Q55kGPjjXInyczHXr/SP1bvmTiN90oXzqP17GA+GkhVq7dE1/M/R3/e9W6Pew7cOLMNpnCQzn+bTTrNuznnedaqcgLQCrwfGYu2EhcnFP/OxEREZEA16ZZWWb80JMben5Hg1u+5Nehd1CvVtEUe/89+46dVcStXLuHVev2sHf/8TPbZM+Wkcrl8nFr24pULpePyuXyUqlsXgrky0LfFyfy3ucLOHz0FAP73UhwsAaNCSQq8Hymzo0ic6ZQrqlZ2OsoIiIiIuKxOjUKM//ne2jT/Vua3/4VP3zSkZuuK++X94qLi2PCjEgGfPU7i5dtZ8++fwu5bFkzUrlcXtq3rnCmiKtcLh+FCmS94N25D19qS/asYbz60WyOHD3F1x/cokFjAoj+pX2mzo2iSb0S+vCLiIiICBDfX3D+6Hu4ocf3tL93OJ+9cWOyNi09eTKa70Yv591B81m9bi+FC2Sl3XXlqVwuX3whVz4vhQtku+xmlmbGK080J1vWjDz52hSOHDvNyIGdCA+/9PyDkvapmgE2bzvI2qh99O4W4XUUEREREUlF8uXJwowfe9Cx9wjue/IXtu08wvN9m1xV37Z9B44z8JvF9B+6kF17jlG9Un6+/ehWOt1YmdDQ4GTL/kTvBmTLkpEHnv2Vtnd+y9jBXVLFgDbiXyrwgGlzNwCo/52IiIiInCdL5oyMHdyF+54cy4vvzWTbzsN88toNhIRcXjEWtWk/73/xG4N/+JPjJ6Jp07QMj99fn+YNSvptMJT7u0WQLUtGuvcdRcsuXzPhm27kzpnJL+8lqYMKPOKbZ+bLk5kqFfJ5HUVEREREUqHQ0GCGvNeewgWy8frHc9i5+yjDP+lApvAMl3ztwj+38s5n8xk1YTXBwUbX9tX4z33XUrVi/hRIDl3aVyVL5gx0fOBHmnQYwpTv70z10z/IlQv4IXWcc0ydG0XLhqU0jKyIiIiIXJCZ8dpTLRjw6vX8Om0tLTp/zd79xxLdNi4ujjGT1tDo1sHUa/cFU+as58kHGrBxfl+GvNc+xYq7f9x0XXkmfN2NjVsP0vDWwWzYfCBF319STsAXeCvW7Gb33mNqnikiIiIiSfJgj7qM/KwTf67cQYNbBrNxy7/F0okT0Xz27WIqNhtA+3uHs2XHIT54sQ1bFv6Hfk+3pFCBbJ7lbla/JNOG9+DAoRM0um0wayL3eJZF/CfgC7ypc6MAaNGwpMdJRERERCStuLVtJaZ+fye79x3j2vZfMm1uFC9/MJPi175P72d+JWvmDAwf0IHIOY/w6D31yJolo9eRAbimZhFmjuhJTGwcjW4bwh/Lt3sdSZKZCry5UZQrlZtihXN4HUVERERE0pCGdYszb9TdhIYE0bLL17zw7sz4AurHniwa14vb21W57IFYUkK1igWY89PdZAoPpdntXzH3901eR5JkFNAF3unTMcz6baOaZ4qIiIjIFalULh8LRt/LS481ZeW0B/llyB00ubZEqh/boWzJ3Mz56S4K5M1Cq67fMGlmpNeRJJkEdIG38M9tHDserQJPRERERK5Y4YLZeL5vUyqVS1sjshcrnIPZI++iXKnc3HT394yasMrrSJIMArrAmzo3iqAgo+m1JbyOIiIiIiKS4vLnzcKMH3oSUa0QHXuP4KsRS72OJFcpoOfBmzo3iohqhciZI9zrKCIikg6ZWRvgQyAY+MI598Y5z78PNPMtZgLyOedy+J6LBZb7ntvsnGuXIqFFJODkzBHO5O+60/7e4fT8z2iOHDtFn57XeB2LqXPW8+L7Mzl5MobG1xSn8TXFaXRNcU3UfgkBW+AdPnKShX9u5akHGnodRURE0iEzCwYGANcBW4FFZjbWOXemDZRz7v8SbP8wUDPBLk4452qkUFwRCXBZMmfk1yF30PmhkTz83AT2HTjBMw81JEOGlC8X/li+naf7TWXKnCiKF8lOiSI5+OSbRbz/xW8AVCmfjyb1ip8p+grk06TtCfn1XywJ31w2Bj4AqgGdnXMj/ZknoVm/bSI21tGykfrfiYiIX9QFIp1zUQBmNhy4GbhQJ5cuwAsplE1E5DxhYaGMGNiJux8fw4vvzWTQd0t45O5r6HVH7RRp8bZ+437+9/Z0ho9dQe6c4bz/Qmse6F6HjBlDOHUqhkV/bWPWb5uYvXATQ0csZcBXiwAoVyr3mWKvSb3iAT86vt8KvKR8cwlsBnoCj/srx4VMnRtFeFgI19YqktJvLSIigaEwsCXB8lYg0TZPZlYcKAlMT7A6zMwWAzHAG8650X7KKSJyRmhoMF9/cAt3tK/Ku4Pm83S/qbzy4Szu6VyLvvfUo2SxnMn+nrv3HuWVD2cz8NvFhIYE8d+HG/FE7wZkzxZ2ZpuMGUNoWLc4DesW579AdHQsf67YweyF8QXfyPGr+GLYHwAUL5KdJvVKnCn6ypTIlepHNU1O/ryDd8lvLp1zG33PxfkxR6Kmzo2iUd3ihIWFpvRbi4iInKszMNI5F5tgXXHn3DYzKwVMN7Plzrn1577QzHoBvQCKFSuWMmlFJF0zM9o2K0vbZmVZunIH732+gE++XsTHQ3/n1rYVefz++lxT8+pvkhw5eor3Pl/AO5/N58TJaO7rUpvn+zahYP5LN7kMDQ2mbs0i1K1ZhMd7NyA2No4Vf+9m9sJNzPptIxNmrOPrkX8BUDBfFprVL8nNrcrTpmkZsmUNu8Te0zZ/FnhJ/uYypW3feZhVa/fQs2MNr6OIiEj6tQ0ommC5iG9dYjoDDyVc4Zzb5vsdZWYzie+fd16B55wbBAwCiIiIcFedWkQkgRqVC/L1B7fS76mW9B+6kIHfLmbkuFU0qFOUx+6rT7tW5QkOvryB+U+fjuHz7//g5Q9nsXvvMTrcUIlXn2hO+dJ5rjhncHAQ1SsVoHqlAjx81zU45/h7/V5m/RZf8E2Zs57vRy8nQ4ZgWjQoSfvWFWh3Xfl02X8vTQyyktzfTk6btwFA89+JiIg/LQLKmllJ4gu7zsAd525kZhWAnMCCBOtyAsedc6fMLA/QAHgrRVKLiCSicMFsvPHMdfzvkcYM/uFPPvjyN27t9QOli+fk/+69lp6dapA5U4aL7iMuLo4Rv67iv29NY/2mAzSpV5yxg7sky93Ac5kZFcrkpUKZvNzfLYLY2DgWLNnC6Elr+HniGu5/+ld6P/Mr9WoVoX3rCrRvXYFypa68wExNzDn/fNlnZtcCLzrnWvuWnwFwzvVLZNuhwK9JGWQlIiLCLV68+Kqy9fi/nxk3bS27lz5BUFBATwUoIpKqmdkS51yE1zmulJldT/xgYsHAYOfca2b2MrDYOTfWt82LQJhz7ukEr6sPfAbEET9n7QfOuS8v9X7JcY4UEUmKmJhYRk9awzufzWfhn9vIlSOc3t0i6NOzbqJNLKfNjeKp16ewZPkOqlbIx5vPXkebpmU86RvnnGPl37sZPWkNoyetYcnyHQBULJuH9q3ii72I6oWuuk6IiYll87ZDRG7cf9ZP+9YVuLtzrava98XOj/4s8EKAtUAL4r+5XATc4Zxbmci2Q0mhAs85R5E679GwTjF++LTjFe9HRET8L60XeClNBZ6IpDTnHPMXb+HdQfMZPWkNoaHB3HFzVR7rdS1VKuTnzxU7eLrfVCbPXk+xwtl59Ynm3NG+6mU36/SnzdsOMnbK34yetIaZCzYSG+solD8rN7cqT/vWFWh6bYkLThdx6lQMG7YcIHLjftZvOnBWIbdx60FiYv4daiQ8LITSxXPRu1sED/Wse1WZPSnwfG980W8uzawO8DPxTVNOAjudc5Uvts+rPXmtXreHSs0HMOjNm7jvjtpXvB8REfE/FXiXRwWeiHgpcsM+PvjyN4b8uJTjJ6KpUbkAS1fuJFeOcP73SGMe6B6R6gc4PHDwBOOmr2X0pDVMnBnJsePRZMuakRual6Vlw1LsO3iC9Zv+LeI2bztEwnIqa5YMlC2Zm9LFc1KmeC7KlPj3p2D+rMl2x9KzAs8frvbk1X/IQh55fgJR8x71yzCvIiKSfFTgXR4VeCKSGuw/cJyB3y5mxLhVtG1ahqcebHjWlAdpxYkT0UybF8XoSWsYO+Vv9uw7DkCeXJniC7gExVtpXzGXJ1emFGl2qgIvgZMno1n013YaXVM8GVOJiIg/qMC7PCrwRET8IzY2jnUb9lEgbxZyZPf/pO+XcrHzY5oYRTM5hYWFqrgTEREREZEkCw4OokKZvF7HSJLU07tRRERERERErooKPBERERERkXRCBZ6IiIiIiEg6oQJPREREREQknVCBJyIiIiIikk6owBMREREREUknVOCJiIiIiIikEyrwRERERERE0gkVeCIiIiIiIumECjwREREREZF0wpxzXme4LGa2B9h0lbvJA+xNhjjpjY7L+XRMzqdjcj4dk/Ml1zEp7pzLmwz7CQg6R/qNjsn5dEzOp2OSOB2X8yXHMbng+THNFXjJwcwWO+civM6R2ui4nE/H5Hw6JufTMTmfjknapX+78+mYnE/H5Hw6JonTcTmfv4+JmmiKiIiIiIikEyrwRERERERE0olALfAGeR0gldJxOZ+Oyfl0TM6nY3I+HZO0S/9259MxOZ+Oyfl0TBKn43I+vx6TgOyDJyIiIiIikh4F6h08ERERERGRdCfgCjwza2Nmf5tZpJk97XUeL5hZUTObYWarzGylmT3qW5/LzKaY2Trf75xeZ01pZhZsZn+a2a++5ZJmttD3efnBzDJ4nTElmVkOMxtpZmvMbLWZXRvonxMz+z/ffzcrzGyYmYUF4ufEzAab2W4zW5FgXaKfDYv3ke/4LDOzWt4llwvR+TGezpGJ0/nxfDpHnk/nyNRxfgyoAs/MgoEBQFugEtDFzCp5m8oTMcBjzrlKQD3gId9xeBqY5pwrC0zzLQeaR4HVCZbfBN53zpUBDgD3eJLKOx8CE51zFYDqxB+bgP2cmFlh4BEgwjlXBQgGOhOYn5OhQJtz1l3os9EWKOv76QV8mkIZJYl0fjyLzpGJ0/nxfDpHJqBz5BlD8fj8GFAFHlAXiHTORTnnTgPDgZs9zpTinHM7nHN/+B4fIf5/SIWJPxZf+Tb7CmjvSUCPmFkR4AbgC9+yAc2Bkb5NAuqYmFl2oDHwJYBz7rRz7iAB/jkBQoBwMwsBMgE7CMDPiXNuNrD/nNUX+mzcDHzt4v0G5DCzgikSVJJK50cfnSPPp/Pj+XSOvKCAP0emhvNjoBV4hYEtCZa3+tYFLDMrAdQEFgL5nXM7fE/tBPJ7lcsjHwBPAnG+5dzAQedcjG850D4vJYE9wBBfs5wvzCwzAfw5cc5tA94BNhN/0joELCGwPycJXeizof/3pn76N0qEzpFnfIDOj+fSOfIcOkdeVIqeHwOtwJMEzCwL8BPQ1zl3OOFzLn541YAZYtXMbgR2O+eWeJ0lFQkBagGfOudqAsc4p6lJAH5OchL/bVtJoBCQmfObYQiB99mQ9EfnyHg6P16QzpHn0DkyaVLicxFoBd42oGiC5SK+dQHHzEKJP3F955wb5Vu965/bwr7fu73K54EGQDsz20h806TmxLetz+FrZgCB93nZCmx1zi30LY8k/mQWyJ+TlsAG59we51w0MIr4z04gf04SutBnQ//vTf30b5SAzpFn0fkxcTpHnk/nyAtL0fNjoBV4i4CyvtF8MhDf8XOsx5lSnK/t/JfAaufcewmeGgv08D3uAYxJ6Wxecc4945wr4pwrQfznYrpzriswA+jg2yzQjslOYIuZlfetagGsIoA/J8Q3O6lnZpl8/x39c0wC9nNyjgt9NsYCd/pGC6sHHErQVEVSB50ffXSOPJvOj4nTOTJROkdeWIqeHwNuonMzu574tuTBwGDn3GveJkp5ZtYQmAMs59/29M8S38fgR6AYsAno5Jw7t5NoumdmTYHHnXM3mlkp4r+xzAX8CXRzzp3yMF6KMrMaxHeqzwBEAXcR/8VQwH5OzOwl4HbiR9r7E7iX+PbyAfU5MbNhQFMgD7ALeAEYTSKfDd+J/mPim+ocB+5yzi32ILZchM6P8XSOvDCdH8+mc+T5dI5MHefHgCvwRERERERE0qtAa6IpIiIiIiKSbqnAExERERERSSdU4ImIiIiIiKQTKvBERERERETSCRV4IiIiIiIi6YQKPJEUZGaxZrbUzFaY2S9mlsPP79fTzD7253uIiIhcLZ0fRZKPCjyRlHXCOVfDOVcF2A885HUgERGRVEDnR5FkogJPxDsLiJ/8EzOrYWa/mdkyM/vZzHL61s80swjf4zxmttH3uKeZjTKziWa2zsze+menZnaXma01s9+BBin+V4mIiFwdnR9FroIKPBEPmFkw0AIY61v1NfCUc64asBx4IQm7qQHcDlQFbjezomZWEHiJ+BNXQ6BSMkcXERHxG50fRa6eCjyRlBVuZkuBnUB+YIqZZQdyOOdm+bb5CmichH1Nc84dcs6dBFYBxYFrgJnOuT3OudPAD8n+F4iIiCQ/nR9FkokKPJGUdcI5V4P4k41x6T4GMfz732nYOc+dSvA4FghJjoAiIiIe0PlRJJmowBPxgHPuOPAI8BhwDDhgZo18T3cH/vm2ciNQ2/e4QxJ2vRBoYma5zSwU6JhsoUVERPxM50eRq6dvNEQ84pz708yWAV2AHsBAM8sERAF3+TZ7B/jRzHoB45Kwzx1m9iLxHdQPAkuTP7mIiIj/6PwocnXMOed1BhEREREREUkGaqIpIiIiIiKSTqjAExERERERSSdU4ImIiIiIiKQTKvBERERERETSCRV4IiIiIiIi6YQKPBERERERkXRCBZ6IiIiIiEg6oQJPREREREQknfh/F5X9MuMyHiQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plot(train_A_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의뢰2\n",
    "A ; CLIENTNUM, GENDER, Customer_Age\n",
    "\n",
    "B ; Credit_Limit, Income_Category\n",
    "\n",
    "C ; ATTRIBUTION_FLAG, Dependent_Count, Education_Level, Marital_Status, Native_Bays_Classifier_Attribution_Flag_Card_Category_mon1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768805383</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.99991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>818770008</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.99994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>713982108</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.99998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769911858</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.99987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709106358</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.99998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLIENTNUM     Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
       "0  768805383  Existing Customer            45      M                3   \n",
       "1  818770008  Existing Customer            49      F                5   \n",
       "2  713982108  Existing Customer            51      M                3   \n",
       "3  769911858  Existing Customer            40      F                4   \n",
       "4  709106358  Existing Customer            40      M                3   \n",
       "\n",
       "  Education_Level Marital_Status Income_Category Card_Category  \\\n",
       "0     High School        Married     $60K - $80K          Blue   \n",
       "1        Graduate         Single  Less than $40K          Blue   \n",
       "2        Graduate        Married    $80K - $120K          Blue   \n",
       "3     High School        Unknown  Less than $40K          Blue   \n",
       "4      Uneducated        Married     $60K - $80K          Blue   \n",
       "\n",
       "   Months_on_book  ...  Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  \\\n",
       "0              39  ...       12691.0                  777          11914.0   \n",
       "1              44  ...        8256.0                  864           7392.0   \n",
       "2              36  ...        3418.0                    0           3418.0   \n",
       "3              34  ...        3313.0                 2517            796.0   \n",
       "4              21  ...        4716.0                    0           4716.0   \n",
       "\n",
       "   Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
       "0                 1.335             1144              42                1.625   \n",
       "1                 1.541             1291              33                3.714   \n",
       "2                 2.594             1887              20                2.333   \n",
       "3                 1.405             1171              20                2.333   \n",
       "4                 2.175              816              28                2.500   \n",
       "\n",
       "   Avg_Utilization_Ratio  \\\n",
       "0                  0.061   \n",
       "1                  0.105   \n",
       "2                  0.000   \n",
       "3                  0.760   \n",
       "4                  0.000   \n",
       "\n",
       "   Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1  \\\n",
       "0                                           0.000093                                                                                    \n",
       "1                                           0.000057                                                                                    \n",
       "2                                           0.000021                                                                                    \n",
       "3                                           0.000134                                                                                    \n",
       "4                                           0.000022                                                                                    \n",
       "\n",
       "   Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2  \n",
       "0                                            0.99991                                                                                   \n",
       "1                                            0.99994                                                                                   \n",
       "2                                            0.99998                                                                                   \n",
       "3                                            0.99987                                                                                   \n",
       "4                                            0.99998                                                                                   \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_col = ['CLIENTNUM', 'Gender', 'Customer_Age']\n",
    "B_col = ['Credit_Limit', 'Income_Category']\n",
    "C_col = ['Attrition_Flag', 'Dependent_count', 'Education_Level', 'Marital_Status', \n",
    "         'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
    "         'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2']\n",
    "\n",
    "data = pd.read_csv('BankChurners.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1] Index(['Existing Customer', 'Attrited Customer'], dtype='object')\n",
      "[0 1 0 ... 1 0 1] Index(['M', 'F'], dtype='object')\n",
      "[0 1 1 ... 0 1 1] Index(['High School', 'Graduate', 'Uneducated', 'Unknown', 'College',\n",
      "       'Post-Graduate', 'Doctorate'],\n",
      "      dtype='object')\n",
      "[0 1 0 ... 0 2 0] Index(['Married', 'Single', 'Unknown', 'Divorced'], dtype='object')\n",
      "[0 1 2 ... 1 3 1] Index(['$60K - $80K', 'Less than $40K', '$80K - $120K', '$40K - $60K',\n",
      "       '$120K +', 'Unknown'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768805383</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Blue</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.999910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>818770008</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Blue</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.999940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>713982108</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769911858</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Blue</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.999870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709106358</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Blue</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>772366833</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Blue</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1851</td>\n",
       "      <td>2152.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>15476</td>\n",
       "      <td>117</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.999810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>710638233</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Blue</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>4277.0</td>\n",
       "      <td>2186</td>\n",
       "      <td>2091.0</td>\n",
       "      <td>0.804</td>\n",
       "      <td>8764</td>\n",
       "      <td>69</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.995270</td>\n",
       "      <td>0.004729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>716506083</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>0.819</td>\n",
       "      <td>10291</td>\n",
       "      <td>60</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.997880</td>\n",
       "      <td>0.002118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>717406983</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0.535</td>\n",
       "      <td>8395</td>\n",
       "      <td>62</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>0.003294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>714337233</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Silver</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>10388.0</td>\n",
       "      <td>1961</td>\n",
       "      <td>8427.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>10294</td>\n",
       "      <td>61</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.996620</td>\n",
       "      <td>0.003377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10127 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CLIENTNUM  Attrition_Flag  Customer_Age  Gender  Dependent_count  \\\n",
       "0      768805383               0            45       0                3   \n",
       "1      818770008               0            49       1                5   \n",
       "2      713982108               0            51       0                3   \n",
       "3      769911858               0            40       1                4   \n",
       "4      709106358               0            40       0                3   \n",
       "...          ...             ...           ...     ...              ...   \n",
       "10122  772366833               0            50       0                2   \n",
       "10123  710638233               1            41       0                2   \n",
       "10124  716506083               1            44       1                1   \n",
       "10125  717406983               1            30       0                2   \n",
       "10126  714337233               1            43       1                2   \n",
       "\n",
       "       Education_Level  Marital_Status  Income_Category Card_Category  \\\n",
       "0                    0               0                0          Blue   \n",
       "1                    1               1                1          Blue   \n",
       "2                    1               0                2          Blue   \n",
       "3                    0               2                1          Blue   \n",
       "4                    2               0                0          Blue   \n",
       "...                ...             ...              ...           ...   \n",
       "10122                1               1                3          Blue   \n",
       "10123                3               3                3          Blue   \n",
       "10124                0               0                1          Blue   \n",
       "10125                1               2                3          Blue   \n",
       "10126                1               0                1        Silver   \n",
       "\n",
       "       Months_on_book  ...  Credit_Limit  Total_Revolving_Bal  \\\n",
       "0                  39  ...       12691.0                  777   \n",
       "1                  44  ...        8256.0                  864   \n",
       "2                  36  ...        3418.0                    0   \n",
       "3                  34  ...        3313.0                 2517   \n",
       "4                  21  ...        4716.0                    0   \n",
       "...               ...  ...           ...                  ...   \n",
       "10122              40  ...        4003.0                 1851   \n",
       "10123              25  ...        4277.0                 2186   \n",
       "10124              36  ...        5409.0                    0   \n",
       "10125              36  ...        5281.0                    0   \n",
       "10126              25  ...       10388.0                 1961   \n",
       "\n",
       "       Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  \\\n",
       "0              11914.0                 1.335             1144              42   \n",
       "1               7392.0                 1.541             1291              33   \n",
       "2               3418.0                 2.594             1887              20   \n",
       "3                796.0                 1.405             1171              20   \n",
       "4               4716.0                 2.175              816              28   \n",
       "...                ...                   ...              ...             ...   \n",
       "10122           2152.0                 0.703            15476             117   \n",
       "10123           2091.0                 0.804             8764              69   \n",
       "10124           5409.0                 0.819            10291              60   \n",
       "10125           5281.0                 0.535             8395              62   \n",
       "10126           8427.0                 0.703            10294              61   \n",
       "\n",
       "       Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \\\n",
       "0                    1.625                  0.061   \n",
       "1                    3.714                  0.105   \n",
       "2                    2.333                  0.000   \n",
       "3                    2.333                  0.760   \n",
       "4                    2.500                  0.000   \n",
       "...                    ...                    ...   \n",
       "10122                0.857                  0.462   \n",
       "10123                0.683                  0.511   \n",
       "10124                0.818                  0.000   \n",
       "10125                0.722                  0.000   \n",
       "10126                0.649                  0.189   \n",
       "\n",
       "       Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1  \\\n",
       "0                                               0.000093                                                                                    \n",
       "1                                               0.000057                                                                                    \n",
       "2                                               0.000021                                                                                    \n",
       "3                                               0.000134                                                                                    \n",
       "4                                               0.000022                                                                                    \n",
       "...                                                  ...                                                                                    \n",
       "10122                                           0.000191                                                                                    \n",
       "10123                                           0.995270                                                                                    \n",
       "10124                                           0.997880                                                                                    \n",
       "10125                                           0.996710                                                                                    \n",
       "10126                                           0.996620                                                                                    \n",
       "\n",
       "       Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2  \n",
       "0                                               0.999910                                                                                   \n",
       "1                                               0.999940                                                                                   \n",
       "2                                               0.999980                                                                                   \n",
       "3                                               0.999870                                                                                   \n",
       "4                                               0.999980                                                                                   \n",
       "...                                                  ...                                                                                   \n",
       "10122                                           0.999810                                                                                   \n",
       "10123                                           0.004729                                                                                   \n",
       "10124                                           0.002118                                                                                   \n",
       "10125                                           0.003294                                                                                   \n",
       "10126                                           0.003377                                                                                   \n",
       "\n",
       "[10127 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attrition_Flag, Attrition_Flag_label=data['Attrition_Flag'].factorize()\n",
    "Gender, Gender_label=data['Gender'].factorize()\n",
    "Education_Level, Education_Level_label=data['Education_Level'].factorize()\n",
    "Marital_Status, Marital_Status_label=data['Marital_Status'].factorize()\n",
    "Income_Category, Income_Category_label=data['Income_Category'].factorize()\n",
    "\n",
    "\n",
    "print(Attrition_Flag, Attrition_Flag_label)\n",
    "print(Gender, Gender_label)\n",
    "print(Education_Level, Education_Level_label)\n",
    "print(Marital_Status, Marital_Status_label)\n",
    "print(Income_Category, Income_Category_label)\n",
    "\n",
    "\n",
    "\n",
    "data['Attrition_Flag'] = Attrition_Flag\n",
    "data['Gender'] = Gender\n",
    "data['Education_Level'] = Education_Level\n",
    "data['Marital_Status'] = Marital_Status\n",
    "data['Income_Category'] = Income_Category\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.999910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.999940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.999870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.999810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995270</td>\n",
       "      <td>0.004729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997880</td>\n",
       "      <td>0.002118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>0.003294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996620</td>\n",
       "      <td>0.003377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10127 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Attrition_Flag  Dependent_count  Education_Level  Marital_Status  \\\n",
       "0                   0                3                0               0   \n",
       "1                   0                5                1               1   \n",
       "2                   0                3                1               0   \n",
       "3                   0                4                0               2   \n",
       "4                   0                3                2               0   \n",
       "...               ...              ...              ...             ...   \n",
       "10122               0                2                1               1   \n",
       "10123               1                2                3               3   \n",
       "10124               1                1                0               0   \n",
       "10125               1                2                1               2   \n",
       "10126               1                2                1               0   \n",
       "\n",
       "       Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1  \\\n",
       "0                                               0.000093                                                                                    \n",
       "1                                               0.000057                                                                                    \n",
       "2                                               0.000021                                                                                    \n",
       "3                                               0.000134                                                                                    \n",
       "4                                               0.000022                                                                                    \n",
       "...                                                  ...                                                                                    \n",
       "10122                                           0.000191                                                                                    \n",
       "10123                                           0.995270                                                                                    \n",
       "10124                                           0.997880                                                                                    \n",
       "10125                                           0.996710                                                                                    \n",
       "10126                                           0.996620                                                                                    \n",
       "\n",
       "       Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2  \n",
       "0                                               0.999910                                                                                   \n",
       "1                                               0.999940                                                                                   \n",
       "2                                               0.999980                                                                                   \n",
       "3                                               0.999870                                                                                   \n",
       "4                                               0.999980                                                                                   \n",
       "...                                                  ...                                                                                   \n",
       "10122                                           0.999810                                                                                   \n",
       "10123                                           0.004729                                                                                   \n",
       "10124                                           0.002118                                                                                   \n",
       "10125                                           0.003294                                                                                   \n",
       "10126                                           0.003377                                                                                   \n",
       "\n",
       "[10127 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_A_df = data[A_col]\n",
    "train_B_df = data[B_col]\n",
    "train_C_df = data[C_col]\n",
    "train_C_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_col = 'Credit_Limit'\n",
    "\n",
    "use_data = train_A_df\n",
    "\n",
    "if target_col in use_data.columns:\n",
    "    use_data.drop([target_col], axis=1, inplace=True)\n",
    "\n",
    "npX=use_data.to_numpy()\n",
    "npY=data[target_col].to_numpy().reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(npX, npY, test_size=0.2)\n",
    "p = X_train.shape[1]\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model_fn(p):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(30, input_dim=p, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1)])\n",
    "    return tff.learning.from_keras_model(keras_model=model,loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                                         input_spec=X_test,\n",
    "                                         metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "\n",
    "def my_train(rounds,clients_per_round, noise_multiplier, divide_train_data, data_frame):\n",
    "    aggregation_factory = tff.learning.model_update_aggregator.dp_aggregator(noise_multiplier, clients_per_round)\n",
    "    learning_process = tff.learning.build_federated_averaging_process(my_model_fn(p),\n",
    "                                                                      client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.01),\n",
    "                                                                      server_optimizer_fn=lambda: tf.keras.optimizers.SGD(1.0, momentum=0.9),\n",
    "                                                                      model_update_aggregation_factory=aggregation_factory)\n",
    "    eval_process = tff.learning.build_federated_evaluation(my_model_fn(p))\n",
    "\n",
    "    # Training loop.\n",
    "    state = learning_process.initialize()\n",
    "    for round in range(rounds):\n",
    "        if round % 5 == 0:\n",
    "            metrics = eval_process(state.model, [X_test])['eval']\n",
    "            if round < 25 or round % 25 == 0:\n",
    "                print(f'Round {round:3d}: {metrics}')\n",
    "            data_frame = data_frame.append({'Round': round,\n",
    "                                            'NoiseMultiplier': noise_multiplier,\n",
    "                                            **metrics}, ignore_index=True)\n",
    "        # Use selected clients for update.\n",
    "        state, metrics = learning_process.next(state, divide_train_data)\n",
    "\n",
    "    metrics = eval_process(state.model, [test_data])['eval']\n",
    "    print(f'Round {rounds:3d}: {metrics}')\n",
    "    data_frame = data_frame.append({'Round': rounds,\n",
    "                                  'NoiseMultiplier': noise_multiplier,\n",
    "                                  **metrics}, ignore_index=True)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The top-level structure in `input_spec` must contain exactly two top-level elements, as it must specify type information for both inputs to and predictions from the model. You passed input spec [[818459733         0        41]\n [718292283         1        52]\n [713442933         0        49]\n ...\n [716373483         1        48]\n [711205758         0        45]\n [712733958         1        46]].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bb22371516d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m train_B_df = my_train(rounds=rounds,clients_per_round=20, \n\u001b[0;32m----> 7\u001b[0;31m                       noise_multiplier=noise_multiplier, divide_train_data=X_train, data_frame=data_frame)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-82a39308b15c>\u001b[0m in \u001b[0;36mmy_train\u001b[0;34m(rounds, clients_per_round, noise_multiplier, divide_train_data, data_frame)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmy_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclients_per_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivide_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0maggregation_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_update_aggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdp_aggregator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclients_per_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     learning_process = tff.learning.build_federated_averaging_process(my_model_fn(p),\n\u001b[0m\u001b[1;32m     15\u001b[0m                                                                       \u001b[0mclient_optimizer_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                                       \u001b[0mserver_optimizer_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-82a39308b15c>\u001b[0m in \u001b[0;36mmy_model_fn\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m      7\u001b[0m     return tff.learning.from_keras_model(keras_model=model,loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n\u001b[1;32m      8\u001b[0m                                          \u001b[0minput_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                          metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/scratch/PR/hyunchan.moon/venv/tf_210_test/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py\u001b[0m in \u001b[0;36mfrom_keras_model\u001b[0;34m(keras_model, loss, input_spec, loss_weights, metrics)\u001b[0m\n\u001b[1;32m    157\u001b[0m                      \u001b[0;34m'exactly two top-level elements, as it must specify type '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                      \u001b[0;34m'information for both inputs to and predictions from the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                      'model. You passed input spec {}.'.format(input_spec))\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputation_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtype_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_structure_of_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The top-level structure in `input_spec` must contain exactly two top-level elements, as it must specify type information for both inputs to and predictions from the model. You passed input spec [[818459733         0        41]\n [718292283         1        52]\n [713442933         0        49]\n ...\n [716373483         1        48]\n [711205758         0        45]\n [712733958         1        46]]."
     ]
    }
   ],
   "source": [
    "data_frame = pd.DataFrame()\n",
    "rounds = 100\n",
    "\n",
    "noise_multiplier= 0.75\n",
    "\n",
    "train_B_df = my_train(rounds=rounds,clients_per_round=20, \n",
    "                      noise_multiplier=noise_multiplier, divide_train_data=X_train, data_frame=data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_210_test",
   "language": "python",
   "name": "tf_210_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
